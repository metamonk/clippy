<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.4</storyId>
    <title>System Audio and Microphone Capture</title>
    <status>drafted</status>
    <generatedAt>2025-10-28</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-4-system-audio-and-microphone-capture.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>a user</asA>
    <iWant>to record system audio and microphone audio alongside screen recording</iWant>
    <soThat>viewers can hear what I'm doing and my commentary</soThat>
    <tasks>
- Task 1: Integrate CoreAudio/AVFoundation for microphone capture
  - Subtask 1.1: Research and select audio capture crate
  - Subtask 1.2: Implement microphone device enumeration
  - Subtask 1.3: Create microphone capture service wrapper
  - Subtask 1.4: Test microphone permission handling
  - Subtask 1.5: Write unit tests for microphone capture
- Task 2: Implement ScreenCaptureKit system audio capture
  - Subtask 2.1: Research ScreenCaptureKit audio APIs
  - Subtask 2.2: Extend existing screen_capture service with audio support
  - Subtask 2.3: Configure audio format (sample rate, channels)
  - Subtask 2.4: Write unit tests for system audio capture
- Task 3: Build recording UI for audio source selection
  - Subtask 3.1: Design AudioSourceSelector component
  - Subtask 3.2: Add checkboxes for system audio, microphone, both, none
  - Subtask 3.3: Integrate with RecordingPanel component
  - Subtask 3.4: Update recordingStore to track audio source preferences
  - Subtask 3.5: Write component tests
- Task 4: Synchronize audio streams with video
  - Subtask 4.1: Implement timestamp-based audio/video sync
  - Subtask 4.2: Buffer audio frames with video frames in frame synchronizer
  - Subtask 4.3: Handle audio drift correction
  - Subtask 4.4: Test sync accuracy (&lt;50ms tolerance)
- Task 5: FFmpeg audio muxing configuration
  - Subtask 5.1: Configure FFmpeg command for multi-audio track input
  - Subtask 5.2: Map system audio and microphone to separate streams
  - Subtask 5.3: Implement audio encoding (AAC codec)
  - Subtask 5.4: Test output MP4 with FFprobe to verify audio tracks
- Task 6: Audio quality validation and testing
  - Subtask 6.1: Test with 5-minute recording for quality issues
  - Subtask 6.2: Validate no audio distortion under normal conditions
  - Subtask 6.3: Test sync accuracy (audio/video &lt;50ms drift)
  - Subtask 6.4: Document known limitations and quality parameters
    </tasks>
  </story>

  <acceptanceCriteria>
1. CoreAudio integration for microphone capture (via AVFoundation or CoreAudio bindings)
2. System audio capture using ScreenCaptureKit audio APIs
3. Recording UI allows selecting audio sources (system, microphone, both, or none)
4. Audio streams synchronized with video during recording
5. FFmpeg muxes audio and video into single MP4 file
6. Audio quality acceptable (no severe distortion or sync issues)
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>clippy Product Requirements Document</title>
        <section>FR002: Screen Recording Capabilities</section>
        <snippet>System shall capture screen recordings with system audio and microphone audio using macOS ScreenCaptureKit API</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>clippy Decision Architecture</title>
        <section>Technology Stack - Native APIs</section>
        <snippet>screencapturekit 0.3.x for screen capture, nokhwa 0.10.9 with input-avfoundation for camera/audio. Multi-stream recording orchestrator coordinates audio/video streams with real-time FFmpeg encoding.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>clippy Decision Architecture</title>
        <section>Novel Pattern 1: Multi-Stream Recording with Real-Time PiP Composition</section>
        <snippet>Capture screen and webcam simultaneously with 3 independent audio tracks (system audio, microphone, webcam mic). FFmpeg muxes all streams into single MP4 with bounded channels (30-frame buffer).</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Epic 2: Recording Foundation - Story 2.4</section>
        <snippet>CoreAudio integration for microphone, ScreenCaptureKit audio APIs for system audio, FFmpeg muxes audio and video into single MP4 file.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-1-screencapturekit-setup-permissions.md</path>
        <title>Story 2.1: ScreenCaptureKit Setup &amp; Permissions</title>
        <section>Completion Notes</section>
        <snippet>Successfully integrated ScreenCaptureKit 0.3.6, implemented macOS permission flow, created services/screen_capture wrapper service.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-2-full-screen-recording-with-video-capture.md</path>
        <title>Story 2.2: Full Screen Recording with Video Capture</title>
        <section>Architecture Context</section>
        <snippet>ScreenCaptureKit integration for full-screen capture at 30 FPS, frame capture loop with streaming API, services/screen_capture/screencapturekit.rs wrapper.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-3-real-time-ffmpeg-encoding-during-recording.md</path>
        <title>Story 2.3: Real-Time FFmpeg Encoding During Recording</title>
        <section>Dev Notes</section>
        <snippet>Real-time encoding pattern applies to audio streams. FFmpeg multi-input muxing, bounded channels (30-frame buffer), services/ffmpeg/encoder.rs handles multi-stream muxing.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src-tauri/src/services/screen_capture/screencapturekit.rs</path>
        <kind>service</kind>
        <symbol>ScreenCapture</symbol>
        <lines>1-50</lines>
        <reason>Existing ScreenCaptureKit wrapper that needs audio capture support extension for system audio</reason>
      </artifact>
      <artifact>
        <path>src-tauri/src/commands/recording.rs</path>
        <kind>command</kind>
        <symbol>start_recording</symbol>
        <lines></lines>
        <reason>Recording command layer that needs RecordingConfig updated with audio source options</reason>
      </artifact>
      <artifact>
        <path>src/stores/recordingStore.ts</path>
        <kind>store</kind>
        <symbol>RecordingState</symbol>
        <lines></lines>
        <reason>Frontend state management needs audio source preferences (system, microphone, both, none)</reason>
      </artifact>
      <artifact>
        <path>src/components/recording/RecordingPanel.tsx</path>
        <kind>component</kind>
        <symbol>RecordingPanel</symbol>
        <lines></lines>
        <reason>Recording UI component where AudioSourceSelector will be integrated</reason>
      </artifact>
      <artifact>
        <path>src/lib/tauri/recording.ts</path>
        <kind>library</kind>
        <symbol>recording module</symbol>
        <lines></lines>
        <reason>Tauri command wrappers for recording functionality</reason>
      </artifact>
    </code>
    <dependencies>
      <node>
        <package>react</package>
        <version>^19.1.0</version>
      </node>
      <node>
        <package>zustand</package>
        <version>^4</version>
      </node>
      <node>
        <package>vitest</package>
        <version>^2</version>
      </node>
      <node>
        <package>@testing-library/react</package>
        <version>^16</version>
      </node>
      <rust>
        <crate>screencapturekit</crate>
        <version>0.3</version>
      </rust>
      <rust>
        <crate>nokhwa</crate>
        <version>0.10</version>
        <features>input-avfoundation</features>
      </rust>
      <rust>
        <crate>ffmpeg-sidecar</crate>
        <version>2.1</version>
      </rust>
      <rust>
        <crate>tokio</crate>
        <version>1</version>
        <features>full</features>
      </rust>
      <rust>
        <crate>tracing</crate>
        <version>0.1</version>
      </rust>
      <rust>
        <crate>anyhow</crate>
        <version>1</version>
      </rust>
      <rust>
        <crate>thiserror</crate>
        <version>1</version>
      </rust>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>Follow services/commands/components layered architecture pattern established in Epic 1</constraint>
    <constraint>Use Tokio async runtime for audio stream coordination (already in dependencies with full features)</constraint>
    <constraint>Implement bounded channels with 30-frame buffer limit for audio streams (same as video pattern from Story 2.3)</constraint>
    <constraint>Audio sample rate must be 48kHz (professional standard per architecture notes)</constraint>
    <constraint>Audio format: PCM float32 during capture, AAC for final encoding (per architecture)</constraint>
    <constraint>Audio/video sync tolerance: &lt;50ms drift (explicit AC requirement)</constraint>
    <constraint>Check microphone permission before capture (similar to camera permission pattern from Story 2.7)</constraint>
    <constraint>Handle missing audio devices gracefully with appropriate error messages</constraint>
    <constraint>Use tracing crate for structured logging (already established pattern)</constraint>
    <constraint>Error handling with anyhow + thiserror (established architecture pattern)</constraint>
    <constraint>All new TypeScript code must follow ESLint rules and Prettier formatting</constraint>
    <constraint>All Rust code must pass cargo clippy and cargo fmt</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>RecordingConfig</name>
      <kind>Rust struct (Tauri command parameter)</kind>
      <signature>struct RecordingConfig { screen_source: Option&lt;String&gt;, audio_sources: AudioSourceConfig, ... }</signature>
      <path>src-tauri/src/commands/recording.rs</path>
      <notes>Needs AudioSourceConfig field added with system_audio: bool, microphone: bool</notes>
    </interface>
    <interface>
      <name>RecordingState</name>
      <kind>TypeScript Zustand store interface</kind>
      <signature>interface RecordingState { status: RecordingStatus, audioSources: { system: boolean, microphone: boolean }, ... }</signature>
      <path>src/stores/recordingStore.ts</path>
      <notes>Needs audioSources field to track user preferences for audio source selection</notes>
    </interface>
    <interface>
      <name>ScreenCapture::new()</name>
      <kind>Rust constructor</kind>
      <signature>pub fn new() -&gt; Result&lt;Self, ScreenCaptureError&gt;</signature>
      <path>src-tauri/src/services/screen_capture/screencapturekit.rs</path>
      <notes>Existing ScreenCaptureKit wrapper - extend with audio capture methods</notes>
    </interface>
    <interface>
      <name>FFmpeg multi-input audio muxing</name>
      <kind>Command-line pattern</kind>
      <signature>ffmpeg -i video.mp4 -i audio1.wav -i audio2.wav -map 0:v -map 1:a -map 2:a output.mp4</signature>
      <path>Architecture pattern from Story 2.3</path>
      <notes>Map multiple audio inputs to separate streams in output MP4</notes>
    </interface>
  </interfaces>

  <tests>
    <standards>Frontend tests use Vitest + React Testing Library with jsdom environment. Rust tests use standard cargo test framework with tracing for debug output. Integration tests verify end-to-end workflows (recording → file creation → FFprobe validation). Manual testing required for audio quality and sync accuracy on real hardware.</standards>
    <locations>
      <location>src/**/*.test.ts</location>
      <location>src/**/*.test.tsx</location>
      <location>src-tauri/src/**/*.rs (inline #[cfg(test)] modules)</location>
    </locations>
    <ideas>
      <idea ac="1">Test microphone device enumeration with mock devices</idea>
      <idea ac="1">Test microphone capture initialization and permission handling</idea>
      <idea ac="1">Test microphone capture teardown and resource cleanup</idea>
      <idea ac="2">Test ScreenCaptureKit audio API configuration (sample rate, channels)</idea>
      <idea ac="2">Test system audio capture stream initialization</idea>
      <idea ac="3">Test AudioSourceSelector component renders checkboxes correctly</idea>
      <idea ac="3">Test recordingStore updates when user toggles audio sources</idea>
      <idea ac="3">Test RecordingPanel integration with AudioSourceSelector</idea>
      <idea ac="4">Test timestamp-based audio/video synchronization logic</idea>
      <idea ac="4">Test audio frame buffering with video frames in frame synchronizer</idea>
      <idea ac="5">Test FFmpeg command generation for multi-audio input</idea>
      <idea ac="5">Test audio stream mapping (-map 0:a -map 1:a)</idea>
      <idea ac="5">Verify output MP4 with FFprobe contains expected audio tracks</idea>
      <idea ac="6">Integration test: 5-minute recording with system audio + mic</idea>
      <idea ac="6">Manual test: Verify no audio distortion or clipping</idea>
      <idea ac="6">Manual test: Measure sync accuracy with known A/V test files</idea>
    </ideas>
  </tests>
</story-context>
